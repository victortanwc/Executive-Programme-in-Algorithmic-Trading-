{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression  \n",
    "逻辑回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import useful packages.  \n",
    "载入有用的程序包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score,log_loss,precision_score,roc_auc_score,confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the dataset.  \n",
    "读入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set=pd.read_csv(\"gold_train.csv\")\n",
    "test_set=pd.read_csv(\"gold_test.csv\")\n",
    "train_col=list(train_set)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X=train_set[train_col]\n",
    "train_y=train_set['target']\n",
    "\n",
    "test_X=test_set[train_col]\n",
    "test_y=test_set['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Return  gold Return_1  gold Return_2  gold Return_3  gold Return_4  \\\n",
      "0  0.012297       0.001726      -0.004428       0.000492      -0.001352   \n",
      "1  0.012797       0.012297       0.001726      -0.004428       0.000492   \n",
      "2 -0.005526       0.012797       0.012297       0.001726      -0.004428   \n",
      "3 -0.001453      -0.005526       0.012797       0.012297       0.001726   \n",
      "4 -0.006796      -0.001453      -0.005526       0.012797       0.012297   \n",
      "\n",
      "   gold Return_5  gold Return_6  gold Return_7  gold Return_8  gold Return_9  \\\n",
      "0       0.009804       0.001240       0.000248       0.009884       0.008577   \n",
      "1      -0.001352       0.009804       0.001240       0.000248       0.009884   \n",
      "2       0.000492      -0.001352       0.009804       0.001240       0.000248   \n",
      "3      -0.004428       0.000492      -0.001352       0.009804       0.001240   \n",
      "4       0.001726      -0.004428       0.000492      -0.001352       0.009804   \n",
      "\n",
      "   ...  gold Return_41  gold Return_42  gold Return_43  gold Return_44  \\\n",
      "0  ...        0.002200       -0.002067       -0.002323       -0.002957   \n",
      "1  ...        0.003872        0.002200       -0.002067       -0.002323   \n",
      "2  ...        0.000386        0.003872        0.002200       -0.002067   \n",
      "3  ...        0.001927        0.000386        0.003872        0.002200   \n",
      "4  ...       -0.003590        0.001927        0.000386        0.003872   \n",
      "\n",
      "   gold Return_45  gold Return_46  gold Return_47  gold Return_48  \\\n",
      "0       -0.001027        0.009084        0.004694        0.002611   \n",
      "1       -0.002957       -0.001027        0.009084        0.004694   \n",
      "2       -0.002323       -0.002957       -0.001027        0.009084   \n",
      "3       -0.002067       -0.002323       -0.002957       -0.001027   \n",
      "4        0.002200       -0.002067       -0.002323       -0.002957   \n",
      "\n",
      "   gold Return_49  gold Return_50  \n",
      "0        0.000522       -0.009595  \n",
      "1        0.002611        0.000522  \n",
      "2        0.004694        0.002611  \n",
      "3        0.009084        0.004694  \n",
      "4       -0.001027        0.009084  \n",
      "\n",
      "[5 rows x 51 columns]\n",
      "0    1\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    1\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_X.head())\n",
    "print(train_y.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(train_X)\n",
    "\n",
    "train_X=scaler.transform(train_X)\n",
    "test_X=scaler.transform(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build model.  \n",
    "建立模型并作出预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_logisticR= linear_model.LogisticRegression(random_state=123)\n",
    "clf_logisticR.fit(train_X,train_y)\n",
    "# get the actual prediction.\n",
    "pred=clf_logisticR.predict(test_X) \n",
    "# get the probility\n",
    "pred_prob=clf_logisticR.predict_proba(test_X) \n",
    "# save the prediction\n",
    "pred_prob_df=pd.DataFrame(pred_prob,columns=[\"pred0\",\"pred1\"])\n",
    "pred_prob_df.to_csv(\"logistic regression.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the metrics, show the performance of the model.  \n",
    "输出指标，得到模型的表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[83, 58],\n",
       "       [60, 49]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_y,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_loss:  0.7251426158986086\n",
      "accuracy:  0.528\n",
      "auc :      0.5065391372242827\n",
      "precision: 0.45794392523364486\n"
     ]
    }
   ],
   "source": [
    "print(\"log_loss: \",log_loss(test_y,pred_prob))\n",
    "print(\"accuracy: \",accuracy_score(test_y,pred))\n",
    "print(\"auc :     \",roc_auc_score(test_y,pred_prob[:,1]))\n",
    "print(\"precision:\",precision_score(test_y,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy at 0.5 threshold:  0.528\n",
      "accuracy at 0.6 threshold:  0.548\n"
     ]
    }
   ],
   "source": [
    "pred=(pred_prob[:,1] > 0.5)\n",
    "print(\"accuracy at 0.5 threshold: \",accuracy_score(test_y,pred))\n",
    "\n",
    "pred=(pred_prob[:,1] > 0.65)\n",
    "print(\"accuracy at 0.6 threshold: \",accuracy_score(test_y,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:                 1000\n",
      "Model:                            GLM   Df Residuals:                      949\n",
      "Model Family:                Binomial   Df Model:                           50\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -669.98\n",
      "Date:                Mon, 12 Oct 2020   Deviance:                       1340.0\n",
      "Time:                        12:10:59   Pearson chi2:                 1.00e+03\n",
      "No. Iterations:                     4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.0291      0.068      0.427      0.669      -0.104       0.163\n",
      "x2            -0.1237      0.071     -1.738      0.082      -0.263       0.016\n",
      "x3            -0.0190      0.069     -0.275      0.784      -0.154       0.116\n",
      "x4            -0.0956      0.069     -1.376      0.169      -0.232       0.041\n",
      "x5             0.0607      0.070      0.865      0.387      -0.077       0.198\n",
      "x6             0.0412      0.070      0.590      0.555      -0.096       0.178\n",
      "x7            -0.0414      0.071     -0.581      0.561      -0.181       0.098\n",
      "x8            -0.0094      0.070     -0.135      0.892      -0.146       0.127\n",
      "x9             0.0718      0.070      1.032      0.302      -0.065       0.208\n",
      "x10            0.0197      0.070      0.281      0.779      -0.118       0.157\n",
      "x11           -0.0722      0.073     -0.995      0.320      -0.215       0.070\n",
      "x12           -0.0621      0.071     -0.873      0.383      -0.202       0.077\n",
      "x13           -0.1152      0.071     -1.617      0.106      -0.255       0.024\n",
      "x14           -0.0368      0.070     -0.530      0.596      -0.173       0.099\n",
      "x15           -0.0935      0.072     -1.293      0.196      -0.235       0.048\n",
      "x16           -0.0385      0.070     -0.550      0.582      -0.176       0.099\n",
      "x17           -0.1105      0.072     -1.545      0.122      -0.251       0.030\n",
      "x18            0.0515      0.070      0.739      0.460      -0.085       0.188\n",
      "x19           -0.0082      0.069     -0.119      0.905      -0.143       0.127\n",
      "x20            0.0027      0.069      0.039      0.969      -0.133       0.138\n",
      "x21            0.0592      0.069      0.856      0.392      -0.076       0.195\n",
      "x22           -0.0152      0.069     -0.220      0.826      -0.151       0.120\n",
      "x23           -0.0092      0.069     -0.132      0.895      -0.145       0.127\n",
      "x24           -0.0908      0.071     -1.285      0.199      -0.229       0.048\n",
      "x25           -0.0413      0.069     -0.596      0.551      -0.177       0.095\n",
      "x26           -0.0561      0.069     -0.817      0.414      -0.191       0.078\n",
      "x27            0.0148      0.069      0.216      0.829      -0.120       0.150\n",
      "x28           -0.0489      0.071     -0.693      0.489      -0.187       0.090\n",
      "x29           -0.0579      0.071     -0.815      0.415      -0.197       0.081\n",
      "x30           -0.0075      0.070     -0.108      0.914      -0.145       0.129\n",
      "x31           -0.0253      0.071     -0.354      0.723      -0.165       0.115\n",
      "x32            0.0560      0.070      0.801      0.423      -0.081       0.193\n",
      "x33           -0.0776      0.071     -1.094      0.274      -0.217       0.061\n",
      "x34            0.0284      0.072      0.396      0.692      -0.112       0.169\n",
      "x35            0.1749      0.075      2.340      0.019       0.028       0.321\n",
      "x36           -0.0147      0.070     -0.211      0.833      -0.152       0.122\n",
      "x37            0.0138      0.068      0.203      0.839      -0.120       0.148\n",
      "x38           -0.0781      0.070     -1.122      0.262      -0.215       0.058\n",
      "x39            0.0745      0.072      1.042      0.298      -0.066       0.215\n",
      "x40           -0.0242      0.069     -0.349      0.727      -0.160       0.112\n",
      "x41            0.0502      0.069      0.726      0.468      -0.085       0.186\n",
      "x42           -0.0615      0.071     -0.861      0.389      -0.201       0.078\n",
      "x43            0.0179      0.070      0.256      0.798      -0.119       0.155\n",
      "x44           -0.0756      0.070     -1.087      0.277      -0.212       0.061\n",
      "x45           -0.0724      0.070     -1.041      0.298      -0.209       0.064\n",
      "x46            0.0950      0.071      1.336      0.181      -0.044       0.234\n",
      "x47           -0.0453      0.069     -0.658      0.510      -0.180       0.090\n",
      "x48            0.1371      0.071      1.943      0.052      -0.001       0.275\n",
      "x49           -0.0509      0.068     -0.750      0.453      -0.184       0.082\n",
      "x50            0.0559      0.067      0.836      0.403      -0.075       0.187\n",
      "x51            0.0741      0.067      1.107      0.268      -0.057       0.205\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "glm_binom = sm.GLM(train_y, train_X, family=sm.families.Binomial())\n",
    "res = glm_binom.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Discriminant Analysis  \n",
    "线性判别分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lda = LinearDiscriminantAnalysis()\n",
    "clf_lda.fit(train_X,train_y)\n",
    "pred=clf_lda.predict(test_X) \n",
    "# get the probility\n",
    "pred_prob=clf_lda.predict_proba(test_X) \n",
    "# save the prediction\n",
    "pred_lda_prob_df=pd.DataFrame(pred_prob,columns=[\"pred0\",\"pred1\"])\n",
    "pred_lda_prob_df.to_csv(\"lda.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[83, 58],\n",
       "       [60, 49]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_y,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy at 0.5 threshold:  0.528\n",
      "accuracy at 0.6 threshold:  0.536\n"
     ]
    }
   ],
   "source": [
    "pred=(pred_prob[:,1] > 0.5)\n",
    "print(\"accuracy at 0.5 threshold: \",accuracy_score(test_y,pred))\n",
    "\n",
    "pred=(pred_prob[:,1] > 0.6)\n",
    "print(\"accuracy at 0.6 threshold: \",accuracy_score(test_y,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_qda = QuadraticDiscriminantAnalysis()\n",
    "clf_qda.fit(train_X,train_y)\n",
    "pred=clf_qda.predict(test_X) \n",
    "# get the probility\n",
    "pred_prob=clf_qda.predict_proba(test_X) \n",
    "# save the prediction\n",
    "pred_qda_prob_df=pd.DataFrame(pred_prob,columns=[\"pred0\",\"pred1\"])\n",
    "pred_qda_prob_df.to_csv(\"qda.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[80, 61],\n",
       "       [63, 46]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_y,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy at 0.5 threshold:  0.504\n",
      "accuracy at 0.8 threshold:  0.54\n"
     ]
    }
   ],
   "source": [
    "pred=(pred_prob[:,1] > 0.5)\n",
    "print(\"accuracy at 0.5 threshold: \",accuracy_score(test_y,pred))\n",
    "\n",
    "pred=(pred_prob[:,1] > 0.8)\n",
    "print(\"accuracy at 0.8 threshold: \",accuracy_score(test_y,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization  \n",
    "正则化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-a3cb2beeb0c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mclf_lasso\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'l1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m123\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mclf_lasso\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m# get the actual prediction.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf_lasso\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1302\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mSAGA\u001b[0m \u001b[0msolver\u001b[0m \u001b[0msupports\u001b[0m \u001b[0mboth\u001b[0m \u001b[0mfloat64\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfloat32\u001b[0m \u001b[0mbit\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m         \"\"\"\n\u001b[1;32m-> 1304\u001b[1;33m         \u001b[0msolver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_solver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36m_check_solver\u001b[1;34m(solver, penalty, dual)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msolver\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'liblinear'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'saga'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mpenalty\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'l2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'none'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 442\u001b[1;33m         raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n\u001b[0m\u001b[0;32m    443\u001b[0m                          \"got %s penalty.\" % (solver, penalty))\n\u001b[0;32m    444\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msolver\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'liblinear'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdual\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty."
     ]
    }
   ],
   "source": [
    "# Logistic Regression with L2 regularizer and regularization strength\n",
    "\n",
    "clf_lasso= linear_model.LogisticRegression(penalty='l1',C=0.5,random_state=123)\n",
    "clf_lasso.fit(train_X,train_y)\n",
    "# get the actual prediction.\n",
    "pred=clf_lasso.predict(test_X) \n",
    "# get the probility\n",
    "pred_prob=clf_lasso.predict_proba(test_X) \n",
    "# save the prediction\n",
    "pred_lasso_prob_df=pd.DataFrame(pred_prob,columns=[\"pred0\",\"pred1\"])\n",
    "pred_lasso_prob_df.to_csv(\"lasso regression.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[99, 42],\n",
       "       [73, 36]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_y,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy at 0.5 threshold:  0.504\n",
      "accuracy at 0.65 threshold:  0.512\n"
     ]
    }
   ],
   "source": [
    "pred=(pred_prob[:,1] > 0.5)\n",
    "print(\"accuracy at 0.5 threshold: \",accuracy_score(test_y,pred))\n",
    "\n",
    "pred=(pred_prob[:,1] > 0.65)\n",
    "print(\"accuracy at 0.65 threshold: \",accuracy_score(test_y,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalty =  l2  and C = 0.00  --> accuracy = 0.5640\n",
      "Penalty =  l2  and C = 0.00  --> accuracy = 0.5440\n",
      "Penalty =  l2  and C = 0.01  --> accuracy = 0.5080\n",
      "Penalty =  l2  and C = 0.10  --> accuracy = 0.5280\n",
      "Penalty =  l2  and C = 1.00  --> accuracy = 0.5280\n",
      "Penalty =  l2  and C = 10.00  --> accuracy = 0.5280\n",
      "Penalty =  l2  and C = 100.00  --> accuracy = 0.5280\n",
      "Penalty =  l2  and C = 1000.00  --> accuracy = 0.5280\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression and Impact of regularizer /regularizing strength\n",
    "penalty_choice=['l2']\n",
    "C_choice=[0.0001,0.001,0.01,0.1,1,10,100,1000]\n",
    "\n",
    "for p in range(len(penalty_choice)):\n",
    "    for c in range(len(C_choice)):\n",
    "        clf_model= linear_model.LogisticRegression(penalty=penalty_choice[p],C=C_choice[c],random_state=123)\n",
    "        clf_model.fit(train_X,train_y)\n",
    "        pred_class=clf_model.predict(test_X)\n",
    "        #print(confusion_matrix(test_y,pred_class))\n",
    "        pred_prob=clf_model.predict_proba(test_X)\n",
    "        print(\"Penalty = \",penalty_choice[p],\" and C = %.2f\"%(C_choice[c]), \" --> accuracy = %.4f\"%accuracy_score(test_y,pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
